[{"objectID":"https://www.maoudia.com/categories/reactive-programming","title":"Reactive programming","type":"category","url":"https://www.maoudia.com/categories/reactive-programming"},{"objectID":"https://www.maoudia.com/categories/tutorial","title":"Tutorial","type":"category","url":"https://www.maoudia.com/categories/tutorial"},{"objectID":"https://www.maoudia.com/author/moncef-aoudia","title":"Moncef AOUDIA","type":"author","url":"https://www.maoudia.com/author/moncef-aoudia"},{"objectID":"https://www.maoudia.com/tags/docker-compose","title":"Docker compose","type":"tag","url":"https://www.maoudia.com/tags/docker-compose"},{"objectID":"https://www.maoudia.com/tags/eip","title":"Eip","type":"tag","url":"https://www.maoudia.com/tags/eip"},{"objectID":"https://www.maoudia.com/tags/java","title":"Java","type":"tag","url":"https://www.maoudia.com/tags/java"},{"objectID":"https://www.maoudia.com/tags/mongodb","title":"Mongodb","type":"tag","url":"https://www.maoudia.com/tags/mongodb"},{"objectID":"https://www.maoudia.com/tags/reactor","title":"Reactor","type":"tag","url":"https://www.maoudia.com/tags/reactor"},{"objectID":"https://www.maoudia.com/tags/spring-boot","title":"Spring boot","type":"tag","url":"https://www.maoudia.com/tags/spring-boot"},{"objectID":"https://www.maoudia.com/tags/spring-data","title":"Spring data","type":"tag","url":"https://www.maoudia.com/tags/spring-data"},{"objectID":"https://www.maoudia.com/tags/spring-webflux","title":"Spring webflux","type":"tag","url":"https://www.maoudia.com/tags/spring-webflux"},{"objectID":"https://www.maoudia.com/tags/testcontainers","title":"Testcontainers","type":"tag","url":"https://www.maoudia.com/tags/testcontainers"},{"objectID":"https://www.maoudia.com/series/mongodb-reactive-cli","title":"Mongodb reactive CLI","type":"series","url":"https://www.maoudia.com/series/mongodb-reactive-cli"},{"author":"Moncef AOUDIA","categories":["Tutorial","Reactive Programming"],"content":"In order to update documents in a MongoDB collection, we often use update requests, if the volume of data is too large, it could lead to performance issues and overconsumption of hardware resources.  We will implement a solution to enrich and update efficiently a large amount of data using Spring Data MongoDB Reactive.  Table of contents 1. EIP content enricher 1.1. Integration flow   2. Project setup 2.1. Requirements 2.2. Generation 2.3. Structure 2.4. Containers 2.5. Data initialization   3. Application 3.1. Configuration 3.2. Implementation 3.3. Demo 3.4. VisuelVM report   4. Integration tests 5. Conclusion 6. Resources   Before continuing the reading, if you are not familiar with Spring reactive stack and MongoDB, I suggest you to check the resources section.  1. EIP content enricher   Enterprise Integration Pattern Content Enricher appends information to an existing message from an external source. It uses information inside the incoming message to perform the enrichment operation.  We will implement a simplified version of the EIP :   Input message : represented by a MongoDB document.   Enricher : our application.   Resource : call to a RESTful API.   Output message : we will keep only the enriched document.    1.1. Integration flow   The application will read the address documents, add the product and save the enriched documents to the MongoDB database.     2. Project setup 2.1. Requirements   Java 1.8+   Maven 3+   Docker Compose   MongoDB Database Tools     2.2. Generation We generate the project skeleton from Spring Initializr.   2.3. Structure 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 . │ .gitignore │ docker-compose.yml │ pom.xml │ README.adoc ├───data │ ├───mongodb │ │ address.ndjson │ └───product │ db.json └───src ├───main │ ├───java │ │ └───com │ │ └───maoudia │ │ └───tutorial │ │ Application.java │ │ AppProperties.java │ │ CollectionService.java │ │ NetworkConfig.java │ └───resources │ application.yml └───test └───java └───com └───maoudia └───tutorial CollectionServiceTest.java     2.4. Containers Download data directory to the root of the project.  We use docker-compose to create the needed containers for this tutorial.  docker-compose.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 services: mongodb: (1) container_name: maoudia-mongodb image: mongo:5.0.8 environment: - MONGO_INITDB_DATABASE=test - MONGO_INITDB_ROOT_USERNAME=admin - MONGO_INITDB_ROOT_PASSWORD=password networks: - mongodb-network ports: - 15015:27017 volumes: - ./data/mongodb:/data/mongodb mongo-express: (2) container_name: maoudia-mongo-express image: mongo-express:0.54.0 depends_on: - mongodb networks: - mongodb-network environment: - ME_CONFIG_MONGODB_SERVER=maoudia-mongodb - ME_CONFIG_MONGODB_ADMINUSERNAME=admin - ME_CONFIG_MONGODB_ADMINPASSWORD=password ports: - 1515:8081 volumes: - ./data/mongodb:/data/mongodb product-api: (3) container_name: maoudia-product-api image: clue/json-server:latest ports: - 1519:80 volumes: - ./data/product/db.json:/data/db.json networks: mongodb-network: driver: bridge      1 MongoDB initialized with the test database.   2 MongoExpress is a MongoDB administration interface.   3 Product API which is configured from db.json file.    We start up the services :  1 docker-compose up -d     2.5. Data initialization We use a JSON document from the French address database.  Address 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 {\u0026#34;id\u0026#34;:\u0026#34;59350\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;municipality\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;Lille\u0026#34;,\u0026#34;postcode\u0026#34;:[\u0026#34;59000\u0026#34;,\u0026#34;59800\u0026#34;,\u0026#34;59260\u0026#34;,\u0026#34;59777\u0026#34;,\u0026#34;59160\u0026#34;],\u0026#34;citycode\u0026#34;:\u0026#34;59350\u0026#34;,\u0026#34;x\u0026#34;:703219.96,\u0026#34;y\u0026#34;:7059335.72,\u0026#34;lon\u0026#34;:3.045433,\u0026#34;lat\u0026#34;:50.630992,\u0026#34;population\u0026#34;:234475,\u0026#34;city\u0026#34;:\u0026#34;Lille\u0026#34;,\u0026#34;context\u0026#34;:\u0026#34;59, Nord, Hauts-de-France\u0026#34;,\u0026#34;importance\u0026#34;:0.56333}    Import address collection :  1 mongoimport --uri \u0026#34;mongodb://admin:password@localhost:15015\u0026#34; --authenticationDatabase=admin --db test --collection address ./data/mongodb/address.ndjson    Ou :  We use MongoExpress which is available at http://localhost:1515.  Product represents a satellite internet offer.  Product 1 2 3 4 5 6 7 {\u0026#34;id\u0026#34;:1,\u0026#34;available\u0026#34;:true,\u0026#34;company\u0026#34;:\u0026#34;SPACEX\u0026#34;,\u0026#34;provider\u0026#34;:\u0026#34;STARLINK\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;SATELLITE\u0026#34;}    Product API is available at http://localhost:1519.     3. Application 3.1. Configuration We change file extension from application.properties to application.yml.  application.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 app: buffer-max-size: 500 bulk-size: 100 collection-name: address enriching-key: product enriching-uri: http://localhost:1519/products/1 spring: main: web-application-type: none data: mongodb: database: test uri: mongodb://admin:password@localhost:15015 --- spring.config.activate.on-profile: dev logging: level: org.mongodb.driver: debug --- spring.config.activate.on-profile: test app: bulk-size: 2    We declare a class which contains application configuration properties.  AppProperties.java 1 2 3 4 5 6 7 8 9 @ConfigurationProperties(prefix = \u0026#34;app\u0026#34;) public class AppProperties { private int bulkSize; private int bufferMaxSize; private String collectionName; private String enrichingKey; private String enrichingUri; // Getter and Setter are omitted }    We create a @Bean of Spring non-blocking HTTP client.  NetworkConfig.java 1 2 3 4 5 6 7 8 9 @Configuration public class NetworkConfig { @Bean public WebClient client() { return WebClient.create(); } }     3.2. Implementation We create a @Service which contains application business logic.  CollectionService.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Service public class CollectionService { private final AppProperties properties; private final ReactiveMongoTemplate template; private final WebClient client; public CollectionService(AppProperties properties, ReactiveMongoTemplate template, WebClient client) { this.properties = properties; this.template = template; this.client = client; } public Flux\u0026lt;BulkWriteResult\u0026gt; enrichAll(String collectionName, String enrichingKey, String enrichingUri) { return template.findAll(Document.class, collectionName) (1) .onBackpressureBuffer(properties.getBufferMaxSize()) (2) .flatMap(document -\u0026gt; enrich(document, enrichingKey, enrichingUri)) (3) .map(CollectionService::toReplaceOneModel) (4) .window(properties.getBulkSize()) (5) .flatMap(replaceOneModelFlux -\u0026gt; bulkWrite(replaceOneModelFlux, collectionName)); (6) } }      1 Creates a stream of documents from the collection.   2 Limits the maximum number of loaded documents in the RAM in case of consumption process is slower than production. If the maximum buffer size is exceeded, an IllegalStateException is thrown.   3 Enriches document asynchronously with the external one.   4 Creates a ReplaceOneModel from document.   5 Group documents into streams of fixed size. The last stream can be smaller.   6 Calls bulk write function.        Configuration property app.bulk-size can be adjusted according to the project needs and available hardware resources. The larger the value of the maximum size, the higher the memory consumption and the size of the requests.      We create document enrichment functions.  CollectionService.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 private Publisher\u0026lt;Document\u0026gt; enrich(Document document, String enrichingKey, String enrichingUri) { (1) return getEnrichingDocument(enrichingUri) .map(enrichingDocument -\u0026gt; { document.put(enrichingKey, enrichingDocument); document.put(\u0026#34;updatedAt\u0026#34;, new Date()); return document; }); } private Mono\u0026lt;Document\u0026gt; getEnrichingDocument(String enrichingUri) { (2) return client.get() .uri(URI.create(enrichingUri)) .retrieve() .bodyToMono(Document.class); }      1 Adds the retrieved document from HTTP call to root of document to be enriched with the key passed in parameter.   2 Retrieves a document from an URI.        MongoDB converts and stores dates in UTC by default.      CollectionService.java 1 2 3 4 5 6 7 8 private static final ReplaceOptions REPLACE_OPTIONS = new ReplaceOptions(); (1) private static ReplaceOneModel\u0026lt;Document\u0026gt; toReplaceOneModel (Document document) { return new ReplaceOneModel\u0026lt;\u0026gt;( Filters.eq(\u0026#34;_id\u0026#34;, document.get(\u0026#34;_id\u0026#34;)), (2) document, (3) REPLACE_OPTIONS ); }      1 Instantiates default replacement configuration.   2 Filter that allows matching by document identifier.   3 Content to be replaced, represents the complete enriched document.    CollectionService.java 1 2 3 4 5 6 private static final BulkWriteOptions BULK_WRITE_OPTIONS = new BulkWriteOptions().ordered(false); (1) private Flux\u0026lt;BulkWriteResult\u0026gt; bulkWrite(Flux\u0026lt;ReplaceOneModel\u0026lt;Document\u0026gt;\u0026gt; updateOneModelFlux, String collectionName) { return updateOneModelFlux.collectList() (2) .flatMapMany(unused -\u0026gt; template.getCollection(collectionName) (3) .flatMapMany(collection -\u0026gt; collection.bulkWrite(updateOneModels, BULK_WRITE_OPTIONS))); (4) }      1 Instantiates writing options with disabling operations order.   2 Collects the stream into a list.   3 Retrieves the collection passed as a parameter.   4 Bulk writes documents into MongoDB collection.        Transactions are supported on Replicaset since MongoDB 4.2. If transactions are enabled, we can use @Transactional or TransactionalOperator to make a method transactional.      We implement the following interfaces:    CommandLineRunner : runs enrichment command at application startup.   ExitCodeGenerator : manages application system exit code.    Application.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @SpringBootApplication(exclude = MongoReactiveRepositoriesAutoConfiguration.class) (1) @ConfigurationPropertiesScan(\u0026#34;com.maoudia.tutorial\u0026#34;) (2) public class Application implements CommandLineRunner, ExitCodeGenerator { private static final Logger LOGGER = LoggerFactory.getLogger(Application.class); private final AppProperties properties; private final CollectionService service; private int exitCode = 255; public static void main(String[] args) { System.exit(SpringApplication.exit(SpringApplication.run(Application.class, args))); } public Application(AppProperties properties, CollectionService service) { this.properties = properties; this.service = service; } @Override public void run(final String... args) { service.enrichAll(properties.getCollectionName(), properties.getEnrichingKey(), properties.getEnrichingUri()) .doOnSubscribe(unused -\u0026gt; LOGGER.info(\u0026#34;------------------\u0026lt; Staring Collection Enriching Command \u0026gt;-------------------\u0026#34;)) (3) .doOnNext(bulkWriteResult -\u0026gt; LOGGER.info(\u0026#34;Bulk write result with {} modified document(s)\u0026#34;, bulkWriteResult.getModifiedCount())) .doOnError(throwable -\u0026gt; { exitCode = 1; LOGGER.error(\u0026#34;Collection enriching failed due to : {}\u0026#34;, throwable.getMessage(), throwable); }) .doOnComplete(() -\u0026gt; exitCode = 0) .doOnTerminate(() -\u0026gt; LOGGER.info(\u0026#34;------------------\u0026lt; Collection Enriching Command Finished \u0026gt;------------------\u0026#34;)) .blockLast(); (4) } @Override public int getExitCode() { return exitCode; } }      1 Disables auto-configuration of repositories, as we use MongoReactiveTemplate only.   2 Allows scanning and detecting beans that carry the @ConfigProperties annotation.   3 Subscribing to stream triggers the processing.   4 Without a running web server, we have to subscribe indefinitely to the Publisher in order to trigger and wait until the end of the execution.     3.3. Demo We launch the application :  1 mvn spring-boot:run    Output :  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 ... 2022-06-10 00:36:45.152 INFO 7036 --- [ main] com.maoudia.tutorial.Application : Started Application in 2.755 seconds (JVM running for 3.251) 2022-06-10 00:36:45.227 INFO 7036 --- [ main] com.maoudia.tutorial.Application : ------------------\u0026lt; Staring Collection Enriching Command \u0026gt;------------------- 2022-06-10 00:36:45.297 INFO 7036 --- [ main] org.mongodb.driver.cluster : No server chosen by com.mongodb.reactivestreams.client.internal.ClientSessionHelper$$Lambda$543/543409470@4647881c from cluster description ClusterDescription{type=UNKNOWN, connectionMode=SINGLE, serverDescriptions=[ServerDescription{address=localhost:15015, type=UNKNOWN, state=CONNECTING}]}. Waiting for 30000 ms before timing out 2022-06-10 00:36:46.527 INFO 7036 --- [localhost:15015] org.mongodb.driver.connection : Opened connection [connectionId{localValue:1, serverValue:39}] to localhost:15015 2022-06-10 00:36:46.527 INFO 7036 --- [localhost:15015] org.mongodb.driver.connection : Opened connection [connectionId{localValue:2, serverValue:40}] to localhost:15015 2022-06-10 00:36:46.527 INFO 7036 --- [localhost:15015] org.mongodb.driver.cluster : Monitor thread successfully connected to server with description ServerDescription{address=localhost:15015, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=61576400} 2022-06-10 00:36:46.692 INFO 7036 --- [ntLoopGroup-2-3] org.mongodb.driver.connection : Opened connection [connectionId{localValue:3, serverValue:41}] to localhost:15015 2022-06-10 00:36:48.355 INFO 7036 --- [ntLoopGroup-2-3] com.maoudia.tutorial.Application : Bulk write result with 100 modified document(s) 2022-06-10 00:36:48.482 INFO 7036 --- [ntLoopGroup-2-4] org.mongodb.driver.connection : Opened connection [connectionId{localValue:4, serverValue:42}] to localhost:15015 2022-06-10 00:36:48.562 INFO 7036 --- [ntLoopGroup-2-3] com.maoudia.tutorial.Application : Bulk write result with 100 modified document(s) 2022-06-10 00:36:48.742 INFO 7036 --- [ntLoopGroup-2-3] com.maoudia.tutorial.Application : Bulk write result with 100 modified document(s) 2022-06-10 00:36:48.982 INFO 7036 --- [ntLoopGroup-2-3] com.maoudia.tutorial.Application : Bulk write result with 100 modified document(s) 2022-06-10 00:36:49.222 INFO 7036 --- [ntLoopGroup-2-3] com.maoudia.tutorial.Application : Bulk write result with 100 modified document(s) 2022-06-10 00:36:49.488 INFO 7036 --- [ntLoopGroup-2-4] com.maoudia.tutorial.Application : Bulk write result with 100 modified document(s) 2022-06-10 00:36:49.701 INFO 7036 --- [ntLoopGroup-2-3] com.maoudia.tutorial.Application : Bulk write result with 100 modified document(s) 2022-06-10 00:36:49.852 INFO 7036 --- [ntLoopGroup-2-3] com.maoudia.tutorial.Application : Bulk write result with 100 modified document(s) 2022-06-10 00:36:50.031 INFO 7036 --- [ntLoopGroup-2-3] com.maoudia.tutorial.Application : Bulk write result with 100 modified document(s) 2022-06-10 00:36:50.105 INFO 7036 --- [ntLoopGroup-2-3] com.maoudia.tutorial.Application : Bulk write result with 100 modified document(s) 2022-06-10 00:36:50.106 INFO 7036 --- [ntLoopGroup-2-3] com.maoudia.tutorial.Application : ------------------\u0026lt; Collection Enriching Command Finished \u0026gt;------------------ [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 17.315 s [INFO] Finished at: 2022-06-10T00:36:54+02:00 [INFO] ------------------------------------------------------------------------ Process finished with exit code 0     3.4. VisuelVM report VisualVM is a lightweight profiling tool. It is used to have an overview of the threads which are launched by the application.    There are two groups of threads that execute operations in parallel, each group forms an event loop.    MongoDB requests are executed by nioEventLoopGroup.   HTTP requests are executed by reactor-http-nio.       4. Integration tests We use JUnit 5 and the Testcontainers MongoDB module for the integration tests. It allows to have a feedback close to the real behaviour of the application which essentially do read/write operations.  To keep this tutorial short, we will only write one test.  CollectionServiceTest.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 @Profile(\u0026#34;test\u0026#34;) @SpringBootTest @Testcontainers (1) class CollectionServiceTest { @Container private static final MongoDBContainer mongoDBContainer = new MongoDBContainer(\u0026#34;mongo:5.0.8\u0026#34;) (2) .withReuse(true); @DynamicPropertySource private static void setProperties(DynamicPropertyRegistry registry) { registry.add(\u0026#34;spring.data.mongodb.uri\u0026#34;, mongoDBContainer::getReplicaSetUrl); (3) } @Autowired private AppProperties properties; @Autowired private CollectionService command; @Autowired private ReactiveMongoTemplate template; @Test void multipleBulkWriteResultsAreReturned() { Document givenDocument1 = new Document(); givenDocument1.put(\u0026#34;_id\u0026#34;, \u0026#34;628ea3edb5110304e5e814f6\u0026#34;); givenDocument1.put(\u0026#34;type\u0026#34;, \u0026#34;municipality\u0026#34;); Document givenDocument2 = new Document(); givenDocument2.put(\u0026#34;_id\u0026#34;, \u0026#34;628ea3edb5110304e5e814f7\u0026#34;); givenDocument2.put(\u0026#34;type\u0026#34;, \u0026#34;street\u0026#34;); Document givenDocument3 = new Document(); givenDocument3.put(\u0026#34;_id\u0026#34;, \u0026#34;628ea3edb5110304e5e814f8\u0026#34;); givenDocument3.put(\u0026#34;type\u0026#34;, \u0026#34;housenumber\u0026#34;); template.insert(Arrays.asList(givenDocument1, givenDocument2, givenDocument3), properties.getCollectionName()).blockLast(); BulkWriteResult expectedBulkWriteResult1 = BulkWriteResult.acknowledged(WriteRequest.Type.REPLACE, 2, 2, Collections.emptyList(), Collections.emptyList()); BulkWriteResult expectedBulkWriteResult2 = BulkWriteResult.acknowledged(WriteRequest.Type.REPLACE, 1, 1, Collections.emptyList(), Collections.emptyList()); command.enrichAll( properties.getCollectionName(), properties.getEnrichingKey() , properties.getEnrichingUri()) .as(StepVerifier::create) (4) .expectNext(expectedBulkWriteResult1) .expectNext(expectedBulkWriteResult2) .verifyComplete(); } }      1 Adds TestContainers Junit 5 extension.   2 Starts a MongoDB container.   3 Sets up application with container’s URI.   4 Uses StepVerifier from Reactor Test to assert output stream.    We launch the integration tests :  1 mvn test -Dspring.profiles.active=test    Test results :  1 2 3 4 5 6 7 8 9 10 11 12 13 ... [INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.563 s - in com.maoudia.tutorial.CollectionServiceTest [INFO] [INFO] Results: [INFO] [INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0 [INFO] [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 32.100 s [INFO] Finished at: 2022-06-10T01:02:17+02:00 [INFO] ------------------------------------------------------------------------      5. Conclusion In this tutorial, we managed to implement a complete solution to enrich and update efficiently a MongoDB collection. Moreover, we have seen how to write integration tests with JUnit 5 and Testcontainers.  The complete source code is available on Github.  In the next chapter of MongoDB Reactive CLI serie, we will add new features and use Picocli to facilitate interactions with the application.    6. Resources   EIP Data enricher   MongoDB Database Tools   French Adresses Data   MongoDB Java Driver Bulk operations   Reactor 3 Reference Guide   Spring Data MongoDB Reference   Web on Reactive Stack   VisualVM   Testcontainers MongoDB     ","language":"en","objectID":"49f0bf334f1906ce110e7c468e4d44fa","tags":["EIP","Java","Reactor","MongoDB","Spring Boot","Spring Data","Spring WebFlux","Docker Compose","TestContainers"],"title":"Bulk Update Spring Data MongoDB Reactive","type":"article","url":"https://www.maoudia.com/blog/bulk-update-with-spring-data-mongodb-reactive/"},{"author":"Moncef AOUDIA","categories":["Tutorial","Reactive Programming"],"content":"Afin de mettre à jour les documents d’une collection MongoDB, on passe souvent par des requêtes de mise à jour, si le volume des données est conséquent, cela peut conduire à des problèmes de performance et une surconsommation des ressources matérielles.  On va implémenter une solution pour enrichir et mettre à jour efficacement un grand volume de données en utilisant Spring Data MongoDB Reactive.  Sommaire 1. EIP enrichisseur de contenu 1.1. Flux d’intégration   2. Configuration du projet 2.1. Prérequis 2.2. Génération 2.3. Structure 2.4. Conteneurs 2.5. Initialisation des données   3. Application 3.1. Configuration 3.2. Implémentation 3.3. Démo 3.4. Rapport VisuelVM   4. Tests d’intégration 5. Conclusion 6. Ressources   Avant de continuer la lecture, si vous n’êtes pas familier avec la pile réactive de Spring et MongoDB, je suggère de consulter la section ressources.  1. EIP enrichisseur de contenu   Le modèle d’intégration d’entreprise enrichisseur de contenu permet d’ajouter des informations à un message existant depuis une source externe. Il utilise les informations contenues dans le message entrant pour effectuer l’opération d’enrichissement.  On va implémenter une version simplifiée de l\u0026#39;EIP :   Message en entrée : représenté par un document MongoDB.   Enrichisseur : notre application.   Ressource : appel à une API RESTful.   Message en sortie : nous ne conserverons que le document enrichi.    1.1. Flux d’intégration   L’application va lire les documents adresse, ajouter le produit et sauvegarder les documents enrichis dans la base MongoDB.     2. Configuration du projet 2.1. Prérequis   Java 1.8+   Maven 3+   Docker Compose   MongoDB Database Tools     2.2. Génération On génère le squelette du projet depuis Spring Initializr.   2.3. Structure 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 . │ .gitignore │ docker-compose.yml │ pom.xml │ README.adoc ├───data │ ├───mongodb │ │ address.ndjson │ └───product │ db.json └───src ├───main │ ├───java │ │ └───com │ │ └───maoudia │ │ └───tutorial │ │ Application.java │ │ AppProperties.java │ │ CollectionService.java │ │ NetworkConfig.java │ └───resources │ application.yml └───test └───java └───com └───maoudia └───tutorial CollectionServiceTest.java     2.4. Conteneurs On télécharge le dossier data vers la racine du projet.  On utilise docker-compose pour créer les conteneurs nécessaires pour ce tutoriel.  docker-compose.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 services: mongodb: (1) container_name: maoudia-mongodb image: mongo:5.0.8 environment: - MONGO_INITDB_DATABASE=test - MONGO_INITDB_ROOT_USERNAME=admin - MONGO_INITDB_ROOT_PASSWORD=password networks: - mongodb-network ports: - 15015:27017 volumes: - ./data/mongodb:/data/mongodb mongo-express: (2) container_name: maoudia-mongo-express image: mongo-express:0.54.0 depends_on: - mongodb networks: - mongodb-network environment: - ME_CONFIG_MONGODB_SERVER=maoudia-mongodb - ME_CONFIG_MONGODB_ADMINUSERNAME=admin - ME_CONFIG_MONGODB_ADMINPASSWORD=password ports: - 1515:8081 volumes: - ./data/mongodb:/data/mongodb product-api: (3) container_name: maoudia-product-api image: clue/json-server:latest ports: - 1519:80 volumes: - ./data/product/db.json:/data/db.json networks: mongodb-network: driver: bridge      1 MongoDB initialisé avec la base de données test.   2 MongoExpress est une interface d’administration MongoDB.   3 L’API produit est configurée depuis le fichier db.json.    On démarre les services :  1 docker-compose up -d     2.5. Initialisation des données On utilise un document JSON issu de la base d’adresses française.  Adresse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 {\u0026#34;id\u0026#34;:\u0026#34;59350\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;municipality\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;Lille\u0026#34;,\u0026#34;postcode\u0026#34;:[\u0026#34;59000\u0026#34;,\u0026#34;59800\u0026#34;,\u0026#34;59260\u0026#34;,\u0026#34;59777\u0026#34;,\u0026#34;59160\u0026#34;],\u0026#34;citycode\u0026#34;:\u0026#34;59350\u0026#34;,\u0026#34;x\u0026#34;:703219.96,\u0026#34;y\u0026#34;:7059335.72,\u0026#34;lon\u0026#34;:3.045433,\u0026#34;lat\u0026#34;:50.630992,\u0026#34;population\u0026#34;:234475,\u0026#34;city\u0026#34;:\u0026#34;Lille\u0026#34;,\u0026#34;context\u0026#34;:\u0026#34;59, Nord, Hauts-de-France\u0026#34;,\u0026#34;importance\u0026#34;:0.56333}    On importe la collection d’adresses :  1 mongoimport --uri \u0026#34;mongodb://admin:password@localhost:15015\u0026#34; --authenticationDatabase=admin --db test --collection address ./data/mongodb/address.ndjson    Ou :  On utilise MongoExpress qui est accessible sur http://localhost:1515.  Le produit représente une offre d’internet par satellite.  Produit 1 2 3 4 5 6 7 {\u0026#34;id\u0026#34;:1,\u0026#34;available\u0026#34;:true,\u0026#34;company\u0026#34;:\u0026#34;SPACEX\u0026#34;,\u0026#34;provider\u0026#34;:\u0026#34;STARLINK\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;SATELLITE\u0026#34;}    L’API produit est accessible sur http://localhost:1519.     3. Application 3.1. Configuration On change l’extension du fichier de application.properties vers application.yml.  application.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 app: buffer-max-size: 500 bulk-size: 100 collection-name: address enriching-key: product enriching-uri: http://localhost:1519/products/1 spring: main: web-application-type: none data: mongodb: database: test uri: mongodb://admin:password@localhost:15015 --- spring.config.activate.on-profile: dev logging: level: org.mongodb.driver: debug --- spring.config.activate.on-profile: test app: bulk-size: 2    On déclare une classe qui va contenir les propriétés de configuration de l’application.  AppProperties.java 1 2 3 4 5 6 7 8 9 @ConfigurationProperties(prefix = \u0026#34;app\u0026#34;) public class AppProperties { private int bulkSize; private int bufferMaxSize; private String collectionName; private String enrichingKey; private String enrichingUri; // Les Getter et Setter sont omis }    On crée un @Bean du client HTTP non bloquant de Spring.  NetworkConfig.java 1 2 3 4 5 6 7 8 9 @Configuration public class NetworkConfig { @Bean public WebClient client() { return WebClient.create(); } }     3.2. Implémentation On crée le @Service qui va contenir la logique métier de l’application.  CollectionService.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Service public class CollectionService { private final AppProperties properties; private final ReactiveMongoTemplate template; private final WebClient client; public CollectionService(AppProperties properties, ReactiveMongoTemplate template, WebClient client) { this.properties = properties; this.template = template; this.client = client; } public Flux\u0026lt;BulkWriteResult\u0026gt; enrichAll(String collectionName, String enrichingKey, String enrichingUri) { return template.findAll(Document.class, collectionName) (1) .onBackpressureBuffer(properties.getBufferMaxSize()) (2) .flatMap(document -\u0026gt; enrich(document, enrichingKey, enrichingUri)) (3) .map(CollectionService::toReplaceOneModel) (4) .window(properties.getBulkSize()) (5) .flatMap(replaceOneModelFlux -\u0026gt; bulkWrite(replaceOneModelFlux, collectionName)); (6) } }      1 Crée un flux de documents à partir de la collection.   2 Limite le nombre maximum de documents chargés dans la RAM en cas de consommation plus lente que la production. Si la taille maximale du tampon est dépassée, une IllegalStateException est levée.   3 Enrichie le document avec le document externe d’une façon asynchrone.   4 Crée un ReplaceOneModel à partir du document.   5 Regroupe les documents en flux de taille fixe. Le dernier flux peut être de taille inférieure.   6 Appel la fonction d’écriture en masse.        La propriété de configuration app.bulk-size peut être ajustée en fonction des besoins et ressources matérielles disponibles. Plus la taille du bulk est grande, plus la consommation de mémoire et la taille des requêtes seront élevées.      On crée les fonctions d’enrichissement de document.  CollectionService.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 private Publisher\u0026lt;Document\u0026gt; enrich(Document document, String enrichingKey, String enrichingUri) { (1) return getEnrichingDocument(enrichingUri) .map(enrichingDocument -\u0026gt; { document.put(enrichingKey, enrichingDocument); document.put(\u0026#34;updatedAt\u0026#34;, new Date()); return document; }); } private Mono\u0026lt;Document\u0026gt; getEnrichingDocument(String enrichingUri) { (2) return client.get() .uri(URI.create(enrichingUri)) .retrieve() .bodyToMono(Document.class); }      1 Ajoute le document récupéré depuis l’appel HTTP à la racine du document à enrichir avec la clef passée en paramètre.   2 Récupère le document depuis l\u0026#39;URI.        MongoDB convertie et stocke les dates en UTC par défaut.      CollectionService.java 1 2 3 4 5 6 7 8 private static final ReplaceOptions REPLACE_OPTIONS = new ReplaceOptions(); (1) private static ReplaceOneModel\u0026lt;Document\u0026gt; toReplaceOneModel (Document document) { return new ReplaceOneModel\u0026lt;\u0026gt;( Filters.eq(\u0026#34;_id\u0026#34;, document.get(\u0026#34;_id\u0026#34;)), (2) document, (3) REPLACE_OPTIONS ); }      1 Instancie la configuration de remplacement par défaut.   2 Le filtre permet la correspondance par identifiant document.   3 Le contenu à remplacer, représente l’intégralité du document enrichi.    CollectionService.java 1 2 3 4 5 6 private static final BulkWriteOptions BULK_WRITE_OPTIONS = new BulkWriteOptions().ordered(false); (1) private Flux\u0026lt;BulkWriteResult\u0026gt; bulkWrite(Flux\u0026lt;ReplaceOneModel\u0026lt;Document\u0026gt;\u0026gt; updateOneModelFlux, String collectionName) { return updateOneModelFlux.collectList() (2) .flatMapMany(unused -\u0026gt; template.getCollection(collectionName) (3) .flatMapMany(collection -\u0026gt; collection.bulkWrite(updateOneModels, BULK_WRITE_OPTIONS))); (4) }      1 Instancie les options d’écritures en désactivant l’ordre des opérations.   2 Collecte le flux dans une liste.   3 Récupère la collection passée en paramètre.   4 Écrit en masse les documents dans la collection MongoDB.        Les transactions sont supportées sur les Replicaset depuis MongoDB 4.2. Si les transactions sont activées, on peut utiliser @Transactional ou TransactionalOperator pour rendre une méthode transactionnelle.      On implémente les interfaces suivantes :    CommandLineRunner : exécute la commande d’enrichissement au démarrage de l’application.   ExitCodeGenerator : gère le code de sortie système.    Application.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 @SpringBootApplication(exclude = MongoReactiveRepositoriesAutoConfiguration.class) (1) @ConfigurationPropertiesScan(\u0026#34;com.maoudia.tutorial\u0026#34;) (2) public class Application implements CommandLineRunner, ExitCodeGenerator { private static final Logger LOGGER = LoggerFactory.getLogger(Application.class); private final AppProperties properties; private final CollectionService service; private int exitCode = 255; public static void main(String[] args) { System.exit(SpringApplication.exit(SpringApplication.run(Application.class, args))); } public Application(AppProperties properties, CollectionService service) { this.properties = properties; this.service = service; } @Override public void run(final String... args) { service.enrichAll(properties.getCollectionName(), properties.getEnrichingKey(), properties.getEnrichingUri()) .doOnSubscribe(unused -\u0026gt; LOGGER.info(\u0026#34;------------------\u0026lt; Staring Collection Enriching Command \u0026gt;-------------------\u0026#34;)) (3) .doOnNext(bulkWriteResult -\u0026gt; LOGGER.info(\u0026#34;Bulk write result with {} modified document(s)\u0026#34;, bulkWriteResult.getModifiedCount())) .doOnError(throwable -\u0026gt; { exitCode = 1; LOGGER.error(\u0026#34;Collection enriching failed due to : {}\u0026#34;, throwable.getMessage(), throwable); }) .doOnComplete(() -\u0026gt; exitCode = 0) .doOnTerminate(() -\u0026gt; LOGGER.info(\u0026#34;------------------\u0026lt; Collection Enriching Command Finished \u0026gt;------------------\u0026#34;)) .blockLast(); (4) } @Override public int getExitCode() { return exitCode; } }      1 Désactive l’auto-configuration des repositories, car on utilise MongoReactiveTemplate seulement.   2 Permet de scanner et détecter les beans qui portent l’annotation @ConfigProperties.   3 L’inscription au flux déclenche le traitement.   4 Sans un serveur web en fonctionnement, nous devons nous abonner indéfiniment au Publisher afin de déclencher et attendre la fin de l’exécution.     3.3. Démo On lance l’application :  1 mvn spring-boot:run    Sortie :  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 ... 2022-06-10 00:36:45.152 INFO 7036 --- [ main] com.maoudia.tutorial.Application : Started Application in 2.755 seconds (JVM running for 3.251) 2022-06-10 00:36:45.227 INFO 7036 --- [ main] com.maoudia.tutorial.Application : ------------------\u0026lt; Staring Collection Enriching Command \u0026gt;------------------- 2022-06-10 00:36:45.297 INFO 7036 --- [ main] org.mongodb.driver.cluster : No server chosen by com.mongodb.reactivestreams.client.internal.ClientSessionHelper$$Lambda$543/543409470@4647881c from cluster description ClusterDescription{type=UNKNOWN, connectionMode=SINGLE, serverDescriptions=[ServerDescription{address=localhost:15015, type=UNKNOWN, state=CONNECTING}]}. Waiting for 30000 ms before timing out 2022-06-10 00:36:46.527 INFO 7036 --- [localhost:15015] org.mongodb.driver.connection : Opened connection [connectionId{localValue:1, serverValue:39}] to localhost:15015 2022-06-10 00:36:46.527 INFO 7036 --- [localhost:15015] org.mongodb.driver.connection : Opened connection [connectionId{localValue:2, serverValue:40}] to localhost:15015 2022-06-10 00:36:46.527 INFO 7036 --- [localhost:15015] org.mongodb.driver.cluster : Monitor thread successfully connected to server with description ServerDescription{address=localhost:15015, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=61576400} 2022-06-10 00:36:46.692 INFO 7036 --- [ntLoopGroup-2-3] org.mongodb.driver.connection : Opened connection [connectionId{localValue:3, serverValue:41}] to localhost:15015 2022-06-10 00:36:48.355 INFO 7036 --- [ntLoopGroup-2-3] com.maoudia.tutorial.Application : Bulk write result with 100 modified document(s) 2022-06-10 00:36:48.482 INFO 7036 --- [ntLoopGroup-2-4] org.mongodb.driver.connection : Opened connection [connectionId{localValue:4, serverValue:42}] to localhost:15015 2022-06-10 00:36:48.562 INFO 7036 --- [ntLoopGroup-2-3] com.maoudia.tutorial.Application : Bulk write result with 100 modified document(s) 2022-06-10 00:36:48.742 INFO 7036 --- [ntLoopGroup-2-3] com.maoudia.tutorial.Application : Bulk write result with 100 modified document(s) 2022-06-10 00:36:48.982 INFO 7036 --- [ntLoopGroup-2-3] com.maoudia.tutorial.Application : Bulk write result with 100 modified document(s) 2022-06-10 00:36:49.222 INFO 7036 --- [ntLoopGroup-2-3] com.maoudia.tutorial.Application : Bulk write result with 100 modified document(s) 2022-06-10 00:36:49.488 INFO 7036 --- [ntLoopGroup-2-4] com.maoudia.tutorial.Application : Bulk write result with 100 modified document(s) 2022-06-10 00:36:49.701 INFO 7036 --- [ntLoopGroup-2-3] com.maoudia.tutorial.Application : Bulk write result with 100 modified document(s) 2022-06-10 00:36:49.852 INFO 7036 --- [ntLoopGroup-2-3] com.maoudia.tutorial.Application : Bulk write result with 100 modified document(s) 2022-06-10 00:36:50.031 INFO 7036 --- [ntLoopGroup-2-3] com.maoudia.tutorial.Application : Bulk write result with 100 modified document(s) 2022-06-10 00:36:50.105 INFO 7036 --- [ntLoopGroup-2-3] com.maoudia.tutorial.Application : Bulk write result with 100 modified document(s) 2022-06-10 00:36:50.106 INFO 7036 --- [ntLoopGroup-2-3] com.maoudia.tutorial.Application : ------------------\u0026lt; Collection Enriching Command Finished \u0026gt;------------------ [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 17.315 s [INFO] Finished at: 2022-06-10T00:36:54+02:00 [INFO] ------------------------------------------------------------------------ Process finished with exit code 0     3.4. Rapport VisuelVM VisualVM est un outil de profilage léger. On l’utilise pour avoir une vue d’ensemble sur les threads qui sont lancés par l’application.    On observe deux groupes de threads qui exécutent les opérations en parallèle, chaque groupe forme une l\u0026#39;event loop.    Les requêtes MongoDB sont exécutées par nioEventLoopGroup.   Les requêtes HTTP sont exécutées par reactor-http-nio.       4. Tests d’intégration On utilise JUnit 5 et le module Testcontainers MongoDB pour les tests d’intégration. Cela permet d’avoir un retour proche du comportement réel de l’application qui fait essentiellement des opérations de lecture/écriture.  Pour que ce tutoriel reste court, on va se contenter d’écrire qu’un seul test.  CollectionServiceTest.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 @Profile(\u0026#34;test\u0026#34;) @SpringBootTest @Testcontainers (1) class CollectionServiceTest { @Container private static final MongoDBContainer mongoDBContainer = new MongoDBContainer(\u0026#34;mongo:5.0.8\u0026#34;) (2) .withReuse(true); @DynamicPropertySource private static void setProperties(DynamicPropertyRegistry registry) { registry.add(\u0026#34;spring.data.mongodb.uri\u0026#34;, mongoDBContainer::getReplicaSetUrl); (3) } @Autowired private AppProperties properties; @Autowired private CollectionService command; @Autowired private ReactiveMongoTemplate template; @Test void multipleBulkWriteResultsAreReturned() { Document givenDocument1 = new Document(); givenDocument1.put(\u0026#34;_id\u0026#34;, \u0026#34;628ea3edb5110304e5e814f6\u0026#34;); givenDocument1.put(\u0026#34;type\u0026#34;, \u0026#34;municipality\u0026#34;); Document givenDocument2 = new Document(); givenDocument2.put(\u0026#34;_id\u0026#34;, \u0026#34;628ea3edb5110304e5e814f7\u0026#34;); givenDocument2.put(\u0026#34;type\u0026#34;, \u0026#34;street\u0026#34;); Document givenDocument3 = new Document(); givenDocument3.put(\u0026#34;_id\u0026#34;, \u0026#34;628ea3edb5110304e5e814f8\u0026#34;); givenDocument3.put(\u0026#34;type\u0026#34;, \u0026#34;housenumber\u0026#34;); template.insert(Arrays.asList(givenDocument1, givenDocument2, givenDocument3), properties.getCollectionName()).blockLast(); BulkWriteResult expectedBulkWriteResult1 = BulkWriteResult.acknowledged(WriteRequest.Type.REPLACE, 2, 2, Collections.emptyList(), Collections.emptyList()); BulkWriteResult expectedBulkWriteResult2 = BulkWriteResult.acknowledged(WriteRequest.Type.REPLACE, 1, 1, Collections.emptyList(), Collections.emptyList()); command.enrichAll( properties.getCollectionName(), properties.getEnrichingKey() , properties.getEnrichingUri()) .as(StepVerifier::create) (4) .expectNext(expectedBulkWriteResult1) .expectNext(expectedBulkWriteResult2) .verifyComplete(); } }      1 Ajoute l’extension Junit 5 de TestContainers.   2 Démarre un conteneur MongoDB.   3 Configure l’application avec l’URI du conteneur.   4 Utilise StepVerifier de Reactor Test pour faire des assertions sur le flux en sortie.    On lance les tests d’intégration :  1 mvn test -Dspring.profiles.active=test    Résultats des tests :  1 2 3 4 5 6 7 8 9 10 11 12 13 ... [INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.563 s - in com.maoudia.tutorial.CollectionServiceTest [INFO] [INFO] Results: [INFO] [INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0 [INFO] [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 32.100 s [INFO] Finished at: 2022-06-10T01:02:17+02:00 [INFO] ------------------------------------------------------------------------      5. Conclusion Dans ce tutoriel, on a réussi à implémenter une solution complète pour enrichir et mettre à jour efficacement une collection MongoDB. De plus, on a vu comment écrire des tests d’intégration avec JUnit 5 et Testcontainers.  Le code source complet est disponible sur Github.  Dans le prochain chapitre de la série MongoDB Reactive CLI, on ajoutera de nouvelles fonctionnalités et utilisera Picocli afin de faciliter les interactions avec l’application.    6. Ressources   EIP Data enricher   MongoDB Database Tools   French Adresses Data   MongoDB Java Driver Bulk operations   Reactor 3 Reference Guide   Spring Data MongoDB Reference   Web on Reactive Stack   VisualVM   Testcontainers MongoDB     ","language":"fr","objectID":"c5e2c9df3707312de51b5d12a9fb99db","tags":["EIP","Java","Reactor","MongoDB","Spring Boot","Spring Data","Spring WebFlux","Docker Compose","TestContainers"],"title":"Mise À Jour En Masse Avec Spring Data MongoDB Reactive","type":"article","url":"https://www.maoudia.com/fr/blog/mise-a-jour-en-masse-avec-spring-data-mongodb-reactive/"},{"author":null,"categories":null,"content":"","language":"en","objectID":"aed2288437af4cb2dc389424e0c47a4c","tags":null,"title":"Offline","type":"offline","url":"https://www.maoudia.com/offline/"},{"author":null,"categories":null,"content":"","language":"fr","objectID":"af1f941b6171f8ad8c4635f399406115","tags":null,"title":"Hors ligne","type":"offline","url":"https://www.maoudia.com/fr/offline/"}]